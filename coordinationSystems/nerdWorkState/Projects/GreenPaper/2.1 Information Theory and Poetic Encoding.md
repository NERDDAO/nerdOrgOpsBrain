## 2.1 Information Theory and Poetic Encoding
### Shannon's Measure of Unexpectedness

Information theory relates to the study of information, its definition, transformation and transmission between parties (C. E. Shannon, 1948). Information theory enabled much of computing and telecommunication. In this context, information can be quantified as the amount of entropy in a given set of data. Entropy is understood as the surprise or predictability of a given symbol given a set of preceding symbols. If an operator is able to predict the next symbol easily the symbol in question has low entropy. 

Claude Shannon's work on information entropy suggests that unexpected or surprising information carries more value and meaning (C. E. Shannon, 1948). This concept is central to the design of kEngrams, which leverage poetic encoding to introduce an element of unexpectedness into knowledge representation.

### 2.4 Information Theory Properties of Poetry
### Information Density

Poetic encoding, particularly through haiku-like structures, allows for high information density (Shannon, 1951). Complex ideas can be distilled into concise, memorable forms, making kEngrams efficient carriers of knowledge within the graph.

By incorporating these elements of unexpectedness, defamiliarization, and information density, kEngrams create a rich, engaging environment for knowledge representation and discovery. This approach not only makes the knowledge graph more valuable but also enhances user engagement and facilitates deeper understanding of complex relationships within the information network.

### Poetic Encoding and Defamiliarization


The use of poetic structures in kEngrams is not merely aesthetic but also serves important information-theoretical purposes:

1. Compression: Poetic forms, particularly haikus, compress complex ideas into concise expressions, allowing for efficient information storage and transmission.
    
2. Entropy and Surprise: Poetry often employs unexpected word choices and juxtapositions, increasing the entropy of the message. This higher entropy correlates with greater information content, making poetic encodings potentially more informative than prosaic ones.
    
3. Redundancy and Error Correction: Poetic devices like rhyme, meter, and alliteration introduce a form of redundancy that can aid in error detection and correction, enhancing the robustness of the encoded information.
    
4. Semantic Density: The use of metaphors and other poetic devices allows for multiple layers of meaning to be encoded in a single phrase, increasing the semantic density of the kEngram.
    
5. Mnemonic Properties: The rhythmic and structural patterns in poetry make the encoded information more memorable, potentially aiding in the retention and recall of knowledge within the system.
    

By leveraging these information-theoretical properties of poetry, kEngrams create a unique and powerful framework for knowledge representation that combines efficiency, depth, and memorability.

## 2.2 Kolmogorov Complexity and Information Compression

Kolmogorov complexity is a fundamental concept in algorithmic information theory, which measures the information content of a string by the length of its shortest possible description.(“Kolmogorov Complexity,” 2024) By encoding information in a condensed form, kEngrams aim to improve information density and facilitate more efficient storage and transmission of knowledge within the decentralized graph. provides a theoretical framework for understanding the compressibility of information. In the context of kEngrams:

1. **Minimal Description Length**: kEngrams aim to represent knowledge in the most concise form possible, aligning with the principle of finding the shortest possible description of information.
    
2. **Algorithmic Randomness**: The poetic structure of kEngrams introduces a degree of randomness that can be analyzed through the lens of Kolmogorov complexity, potentially revealing deeper patterns in the knowledge representation.
    
3. **Compression and Knowledge Discovery**: By compressing information into kEngrams, we may uncover underlying structures and relationships in the data that were not apparent in its uncompressed form.

![[2.3 Semantic Representation and Knowledge Graphs]]
