### Messages

***

**Forwarded from [Raquel Raigal](https://t.me/rraigal)**

- hacer lista de recursos, como servidores, etc.

***

**Forwarded from [Raquel Raigal](https://t.me/rraigal)**

Wallet polygon: matic:0x7AEE7e0e5240E835090E23D2Beb556cB54fa6D0D

***

**Forwarded from [DeFi Spartan](https://t.me/defispartan)**

The spec is ready to build with

Now we are working on getting the spec supported within Lens apps, making spec improvements to improve OpenFrame compatibility, and tooling for frame developers:

- hey.xyz integration (https://github.com/heyxyz/hey/pull/4802) and sample Frames (https://github.com/defispartan/lens-guestbook-frame + existing OpenFrames) should launch this week
- OpenFrames spec and AwesomeOpenFrames docs updates to allow better XMTP / Lens frame compatibility (https://github.com/open-frames/standard/pull/5)
- Frames.js integration (https://github.com/framesjs/frames.js/pull/301). Frame developer package can be tested locally with `yarn link`. Working on functions to support frames.js debugger, hopefully this is the final item for main package launch
- Standalone Frame debugging tool for OpenFrames, built on top of frames.js debugger

***

**Forwarded from [Eneko Uruñuela](https://t.me/eurunuela)**

- I found three datasets that we could use:
  - OpenBookQA is a 4-way multiple choice QA task that requires reasoning with elementary science knowledge, containing 5,957 questions. We use the ofﬁcial data splits from Mihaylov and Frank (2018).
    - I couldn't find the dataset. The paper references a Meta AI website (dataset) that no longer exists.
  - MedQA-USMLE is a 4-way multiple choice QA task that requires biomedical and clinical knowl- edge. The questions are originally from practice tests for the United States Medical License Exams (USMLE). The dataset contains 12,723 questions. We use the original data splits from Jin et al. (2021). 
    - The data and notes on how to analyze it are [GitHub - jind11/MedQA: Code and data for MedQA](https://github.com/jind11/MedQA).
  - CommonsenseQA is a 5-way multiple choice QA task that requires reasoning with commonsense knowledge, containing 12,102 questions. The test set of CommonsenseQA is not publicly available, and model predictions can only be evaluated once every two weeks via the ofﬁcial leaderboard. Hence, we perform main experiments on the in-house (IH) data splits used in Lin et al. (2019), and also report the score of our ﬁnal system on the ofﬁcial test set.
    - The CommonsenseQA dataset can be downloaded from [commonsenseqa](https://www.tau-nlp.sites.tau.ac.il/commonsenseqa).
    - The code used to test LLMs with the dataset is [GitHub - jonathanherzig/commonsenseqa: Author implementation of the paper "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"](https://github.com/jonathanherzig/commonsenseqa).